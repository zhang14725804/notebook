# 50KGopher的面试题是什么样的？
1.项目中用到的锁

* 通过Channel进行安全读写共享变量

* 通过Mutex加锁处理

* 对于Map可以使用sync.Map

* 针对读多写少情况可以使用sync.RWMutex



2.介绍一下线程安全的共享内存方式
共享内存  mutex  现实中大部分情况是读远大于写，可以换为 RWMutex ，并发的读，只有写上锁。
消息传递  goroutine  + channel     
     
3.介绍一下goroutine
goroutine 就是协程，是用户态自己实现的线程，系统级别的线程切换会因为上下文切换，保存现场信息，产生很大的开销，但是用户态的不会，由go语言自己在上层控制，编译器做优化。
goroutine特点。
1) 有独立的栈空间
2) 共享程序堆空间
3) 调度由用户控制
4) 协程是轻量级的线程
和其他语言相比，可以用最简单的方式写出来非常高性能的并发，非常适合快速开发项目。

4.goroutine的自旋占用资源如何解决,gmp
自旋是针对m来讲的，看一下自己有没有直接能用的p, 再看一下本地运行队列是否有需要运行的goroutine,再看一下全局运行队列是否有需要运行的goroutine，
接着有几个判断，
1。如果除了当前工作线程还在运行外，其它工作线程已经处于休眠中，那么也就不用去偷了，肯定没有.
2。下来还有个判断，主要是为了防止因为寻找可运行的goroutine而消耗太多的CPU。因为已经有足够多的工作线程正在寻找可运行的goroutine，让他们去找就好了，自己偷个懒去睡觉
走到这离，现在开始设置 m为自旋，开始尝试去偷其他的工作队列中的p,
当有空闲P又有goroutine需要运行的时候，这个处于自旋状态的M的数量决定了是否需要唤醒或者创建新的工作线程。
挑选出盗取的对象p之后，从盗取p的运行队列中的goroutine队列中批量拿出n/2个goroutine，

为什么是n/2个goroutine？
这里关键点在于读取runqhead和runqtail是两个操作而非一个原子操作，当我们读取runqhead之后但还未读取runqtail之前，如果有其它线程快速的在增加（这是完全有可能的，其它偷取者从队列中偷取goroutine会增加runqhead，而队列的所有者往队列中添加goroutine会增加runqtail）这两个值，则会导致我们读取出来的runqtail已经远远大于我们之前读取出来放在局部变量h里面的runqhead了

盗取算法：
就是循环遍历所有的队列，但是每次循环，都是随机的位置开始的，而且不是按固定的顺序遍历，当然最后都是会遍历完的。
这么做的原因就是保证每个goroutine被获取到的公平性，不能让排后面的永远比前面的优先级低，就不科学了。

如果工作线程经过多次努力一直找不到需要运行的goroutine则调用stopm进入睡眠状态，等待被其它工作线程唤醒。

Note是go runtime实现的一次性睡眠和唤醒机制，一个线程可以通过调用notesleep(*note)进入睡眠状态，而另外一个线程则可以通过notewakeup(*note)把其唤醒**。note的底层实现机制跟操作系统相关，不同系统使用不同的机制，比如linux下使用的futex系统调用，而mac下则是使用的pthread_cond_t条件变量，note对这些底层机制做了一个抽象和封装，这种封装给扩展性带来了很大的好处，比如当睡眠和唤醒功能需要支持新平台时，只需要在note层增加对特定平台的支持即可，不需要修改上层的任何代码。
完美体现golang接口的方便性

全局的milde空闲队列，这样其它运行着的线程一旦发现有更多的goroutine需要运行时就可以通过全局的m空闲队列找到处于睡眠状态的m



5.介绍Linux系统信号
信号是linux系统为了响应某些状况而产生的事件。进程收到信号后应该采取相应的动作
哪些情况会引发信号

1.键盘事件  ctrl +c  ctrl +\
2.非法内存  如果内存管理出错，系统就会发送一个信号进行处理
3.硬件故障  同样的，硬件出现故障系统也会产生一个信号
4.环境切换  比如说从用户态切换到其他态，状态的改变也会发送一个信号，这个信号会告知给系统
SIGHUP
当用户退出Linux登录时，前台进程组和后台有对终端输出的进程将会收到SIGHUP信号。这个信号的默认操作为终止进程，因此前台进程组和后台有终端输出的进程就会中止

SIGINT     
 程序终止(interrupt)信号, 在用户键入INTR字符(通常是Ctrl-C)时发出，用于通知前台进程组终止进程。

6.goroutine抢占时机,gc栈扫描
* 阻塞 I/O
* select操作
* 阻塞在channel
* 等待锁
* 主动调用 runtime.Gosched()
Golang 运行时（runtime）中的系统监控线程 sysmon 可以找出“长时间占用”的 goroutine，从而“提醒”相应的 goroutine 该中断了。
*sysmon在独立的 M（线程）中运行，且不需要绑定 P。
*sysmon 可以找到“长时间占用 P”的 goroutine，但也只是标记 goroutine 应该被抢占了，并无法强制进行 goroutine 的切换。也就是说抢占检查点是编译器预先插入的，在非内联的函数的前面

gc栈扫描
要达到“正确并且高效的扫描”需要 编译期间，运行分配期间，扫描期间 三者配合处理；
内存对齐是非常重要的一个前提条件；
编译期间生成 type 类型，对用户定义的类型全方位分析，标记出所有的指针类型字段；
运行期间，赋值器分配内存的时候，根据 type 结构，设置和对象内存一一对应的 bitmap，标明指针所在位置，以便后续 gc 扫描；
回收器扫描期间，从根部开始扫描，遇到对象，则置灰，投入队列，并且不断的扫描这些对象指向的对象，直到结束。扫描的依据，就根据编译期间生成的 bitmap，分配期间设置的 bitmap 来识别哪些地方有指针，然后进一步处理；
扫描只需要给个开始地址，然后每 8 字节推进就可以扫描了，为了加快效率我们才有了指针的 bitmap (所以这个是个优化项)；
再次强调下，定义的非指针类型不受保护，比如 uintptr 里面就算存储的是一个地址的值，也是不会被扫描到的；

7.Gc触发时机

* gcTriggerHeap 当前分配的内存达到一定阈值时触发，这个阈值在每次GC过后都会根据堆内存的增长情况和CPU占用率来调整；其中分析内存对象大小又分多种情况
* gcTriggerTime 自从上次GC后间隔时间达到了 [runtime.forcegcperiod](https://github.com/golang/go/blob/go1.16/src/runtime/proc.go#L5089-L5094)  时间（默认为2分钟），将启动GC；主要是  [sysmon](https://github.com/golang/go/blob/go1.16/src/runtime/proc.go#L5235-L5243)  监控线程
* gcTriggerCycle 如果当前没有开启垃圾收集，则启动GC；主要是调用函数  [runtime.GC()

这里问题是gc的关键,比如当前用了10M内存,随着程序运行,使用内存不是一个固定的值,在当次GC标记结束后,会更新下一次触发gc的heap大小(gc_trigger),下次GC进入之后会在上述的test()函数中会进行heap大小的比较,如果符合条件就真正进行GC

Golang 以是如何实现这种机制的
在程序启动时，会在一个初始化函数启用一个forcegchelper()  forcegchelper 函数里会通过  [goparkunlock()](https://github.com/golang/go/blob/go1.16/src/runtime/proc.go#L339-L343)  函数主动让自己陷入休眠，然后由 sysmon() 监控线程根据条件来恢复这个gc goroutine。可以看到  [sysmon()](https://github.com/golang/go/blob/go1.16/src/runtime/proc.go#L5096-L5250)  会在一个 for 语句里一直判断这个gcTriggerTime 这个条件是否满足，如果满足的话，会将 forcegc.g 这个 goroutine 添加到全局队列里进行调度(这里 forcegc 是一个全局变量)。

8.是否了解其他gc机制
Java  分代机制
引用计数 基本不用了，循环引用问题

9.内存管理方式
内存提前按大小分配好，相同大小的放在一个链表中，其实就是数组+链表的形式。申请内存的时候，直接按合适的大小返回给用户。

* 内存分配大多时候都是在用户态完成的，不需要频繁进入内核态。
* 每个 P 都有独立的 span cache，多个 CPU 不会并发读写同一块内存，进而减少 CPU L1 cache 的 cacheline 出现 dirty 情况，增大 cpu cache 命中率。
* 内存碎片的问题，Go 是自己在用户态管理的，在 OS 层面看是没有碎片的，使得操作系统层面对碎片的管理压力也会降低。
* mcache 的存在使得内存分配不需要加锁。
当然这不是没有代价的，Go 需要预申请大块内存，这必然会出现一定的浪费，不过好在现在内存比较廉价，不用太在意。
总体上来看，Go 内存管理也是一个金字塔结构：


存的释放过程，没什么特别之处。就是分配的返过程，当 mcache 中存在较多空闲 span 时，会归还给 mcentral；而 mcentral 中存在较多空闲 span 时，会归还给 mheap；mheap 再归还给操作系统


10.Channel分配在堆上还是在栈上？哪些对象分配在堆上？哪些对象分配在栈上？
堆上，当队列满了的时候，会分配在栈上

11.代码效率分析，考虑局部性原理


12.多核CPU下，cache如何保持一致，不冲突
一个是每个cpu更新数据，都发到消息总线上，其他cpu也就知道了，但是代价太大。
一个是用集中状态来区分 数据的状态
cache line具有4中状态，分别是Modified、Exclusive、Shared和Invalid。取其首字母简称MESI。当cache line状态是Modified或者Exclusive状态时，修改其数据不需要发送消息给其他CPU，这在一定程度上减轻了带宽压力。
Exclusive是只有一个cpu有其地址
Shared代表cache line对应的数据在”多”个CPU私有Cache中被缓存，并且其在缓存中的内容与主存的内容一致。

当CPU-0读取0x40数据，数据被缓存到CPU-0私有Cache，此时CPU-1没有缓存0x40数据，所以我们标记cache line状态为Exclusive。Exclusive代表cache line对应的数据仅在数据只在一个CPU的私有Cache中缓存，并且其在缓存中的内容与主存的内容一致。
然后CPU-1读取0x40数据，发送消息给其他CPU，发现数据被缓存到CPU-0私有Cache，数据从CPU-0 Cache返回给CPU-1。此时CPU-0和CPU-1同时缓存0x40数据，此时cache line状态从Exclusive切换到Shared状态。Shared代表cache line对应的数据在"多"个CPU私有Cache中被缓存，并且其在缓存中的内容与主存的内容一致。
继续CPU-0修改0x40地址数据，发现0x40内容所在cache line状态是Shared。CPU-0发出invalid消息传递到其他CPU，这里是CPU-1。CPU-1接收到invalid消息。将0x40所在的cache line置为Invalid状态。Invalid状态表示表明当前cache line无效。然后CPU-0收到CPU-1已经invalid的消息，修改0x40所在的cache line中数据。并更新cache line状态为Modified。Modified表明cache line对应的数据仅在一个CPU私有Cache中被缓存，并且其在缓存中的内容与主存的内容不一致，代表数据被修改。
如果CPU-0继续修改0x40数据，此时发现其对应的cache line的状态是Modified。因此CPU-0不需要向其他CPU发送消息，直接更新数据即可。
如果0x40所在的cache line需要替换，发现cache line状态是Modified。所以数据应该先写回主存。


13.uint类型溢出
报错
Uint类型长度取决于 CPU，如果是32位CPU就是4个字节，如果是64位就是8个字节
14.聊聊rune类型

15.介绍一下channel，有缓冲和无缓冲的区别
可以看成是异步和同步的区别，有缓冲是异步，无缓冲区市同步
16.channel是否线程安全
肯定是了，发送一个数据到Channel 和 从Channel接收一个数据 都是 原子性的。channel 本身就可以当成锁来用。
17.介绍一下Mutex的实现,是悲观锁还是乐观锁


**快速加锁**
采用CAS实现快速加锁
**缓慢加锁（slowLock）**
为了充分提高加锁效率，golang的mutex的运行状态有两种：正常状态和饥饿状态
正常状态下：刚进入锁的协程可通过自旋锁的方式快速获取锁；
饥饿模式下：所有锁的获取者都通过FIFO的方式公平的获取锁资源


自旋锁
从操作系统的角度来看，相比睡眠方式的互斥锁，自旋锁通过自旋占用CPU，避免的CPU的上下文切换，因此在持锁时长较短的情况下，性能更优
Golang的mutex在实现时，充分考虑了自旋锁跟睡眠锁的取舍；即：在持锁时长较短时，采用自旋锁，在持锁时长较大时，采用睡眠锁


乐观锁每次获取数据的时候，都不会担心数据被修改，所以每次获取数据的时候都不会进行加锁，但是在更新数据的时候需要判断该数据是否被别人修改过。
悲观锁在读取数据也会加锁,甚至只能有1个线程可以读取数据。

   golang 的metux 的实现有几个点做法是非常有意思的，一个是底层数据结构上，用了平时很少用的位运算，第二个，用到了自旋，并做了自旋策略控制，最后是用了信号量控制协程。

18.Mutex几种模式?
state
sema
其中，state采用不同位表示不同含义的方式进行定义的，按从低到高位一次排列：
第一位表示加锁状态：0表示未加锁，1表示已加锁
第二位表示唤醒状态：0表示未设置被唤醒状态，1表示已设置被唤醒状态
第三位表示运行状态：0表示正常状态，1表示饥饿状态
第四位以及其他字节位：表示等待获取锁的数目
另外的sema为信号量，通过其P/V操作实现锁的等待和唤醒

19.Muxtez可以做自旋锁?

正常状态下：刚进入锁的协程可通过自旋锁的方式快速获取锁；

20.介绍一下RWMutex
互斥锁在大量读操作的时候效率低下了。
如果读操作较多就建议使用读写锁。
特点：读共享，写独占，写优先


21.介绍一下大对象和小对象，为什么小对象多了会造成gc压力？
常小对象过多会知道GC三色法消耗过多的GPU。优化思路是减少对象分配。

22.介绍项目中遇到的oop情况
23.介绍项目中遇到的坑
24.如果指定指令执行的顺序
当关闭一个channel时，会使得这个channel变得可读。通过这个特性，可以实现一个goroutine执行顺序的技巧。

25.什么是写屏障、混合写屏障，如何实现？
不管是那么屏障，其实都是在加一段代码来记录 对象的操作记录，以便后面垃圾回收的时候知道这些信息，从而知道该不该被删除。

写屏障
如果是纯粹的插入写屏障是满足强三色不变式的(永远不会出现黑色对象指向白色对象)；
但是由于栈上对象无写屏障(不 hook)，那么导致黑色的栈可能指向白色的堆对象，所以必须假定赋值器(mutator)是灰色赋值器，扫描结束之后，必须 STW 重新扫描栈才能确保不丢对象；
STW 重新扫描栈再 goroutine 量大且活跃的场景，延迟不可控，经验值平均 10-100ms；
golang 1.5 之后实现的就是这种类型的插入写屏障。

删除写屏障
删除写屏障也叫基于快照的写屏障方案，必须在起始时，STW 扫描整个栈(注意了，是所有的 goroutine 栈)，保证所有堆上在用的对象都处于灰色保护下，保证的是弱三色不变式；

由于起始快照的原因，起始也是执行 STW，删除写屏障不适用于栈特别大的场景，栈越大，STW 扫描时间越长，对于现代服务器上的程序来说，栈地址空间都很大，所以删除写屏障都不适用，一般适用于很小的栈内存，比如嵌入式，物联网的一些程序；

并且删除写屏障会导致扫描进度(波面)的后退，所以扫描精度不如插入写屏障；


混合写屏障
Golang 1.5 之后已经实现了插入写屏障，但是由于栈对象赋值无法 hook 的原因，导致扫描完之后还有一次 STW 重新扫描栈的整机停顿，混合写屏障就是解决这个问题的。
混合写屏障继承了插入写屏障的优点，起始无需 STW 打快照，直接并发扫描垃圾即可；

混合写屏障继承了删除写屏障的优点，赋值器是黑色赋值器，扫描过一次就不需要扫描了，这样就消除了插入写屏障时期最后 STW 的重新扫描栈；

混合写屏障扫描精度继承了删除写屏障，比插入写屏障更低，随着带来的是 GC 过程全程无 STW；

混合写屏障扫描栈虽然没有 STW，但是扫描某一个具体的栈的时候，还是要停止这个 goroutine 赋值器的工作的哈(针对一个 goroutine 栈来说，是暂停扫的，要么全灰，要么全黑哈，原子状态切换)；

混合写屏障 = 删除写屏障 + 插入写屏障

26.gc的stw是怎么回事
1. 第一个是 GC 将要开始的时候，这个时候主要是一些准备工作，比如 enable write barrier。
2. 第二个过程就是上面提到的 re-scan 过程。如果这个时候没有 stw，那么 mark 将无休止。

27.协程之间是怎么调度的
gmp

28.简单聊聊内存逃逸

Golang程序变量会携带有一组校验数据，用来证明它的整个生命周期是否在运行时完全可知。如果变量通过了这些校验，它就可以在栈上分配。否则就说它 逃逸 了，必须在堆上分配。
能引起变量逃逸到堆上的**典型情况**：
**在方法内把局部变量指针返回** 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出。
**发送指针或带有指针的值到 channel 中。** 在编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。
**在一个切片上存储指针或带指针的值。** 一个典型的例子就是 []*string 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。
**slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap )。** slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。
**在 interface 类型上调用方法。** 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片b 的背后存储都逃逸掉，所以会在堆上分配。


29.为sync.WaitGroup中Wait函数支持 WaitTimeout 功能.
[image:CFFF0FDF-2956-4CB5-87FA-BE5060BDC164-883-00009FADDE1BCAC7/9DC5AFD9-850F-4402-A520-B0FC9F93AE69.png]


30.字符串转成byte数组，会发生内存拷贝吗？
字符串转成切片，会产生拷贝。严格来说，只要是发生类型强转都会发生内存拷贝。那么问题来了。
频繁的内存拷贝操作听起来对性能不大友好。**有没有什么办法可以在字符串转成切片的时候不用发生拷贝呢？**

那么如果想要在底层转换二者，只需要把 StringHeader的地址强转成 SliceHeader就行。那么go有个很强的包叫 unsafe。
1.unsafe.Pointer(&a)方法可以得到变量a的地址。
2.(*reflect.StringHeader)(unsafe.Pointer(&a))可以把字符串a转成底层结构的形式。
3.(*[]byte)(unsafe.Pointer(&ssh))可以把ssh底层结构体转成byte的切片的指针。
4.再通过 *转为指针指向的实际内容。
太复杂一般不用

31.http包的内存泄漏
没有关闭resp.Body，就会导致内存的泄漏。
原来的resp.Body.Close()实现中， 会替你读取和丢弃body中的残留数据。 这样可以确保这个http连接可以被其他请求重用， 比如在一些使能了http长连接的场景中。 最新的Body.Close函数实现是不一样的。现在，需要你自己去读取和丢弃残留的数据。 如果你不这么做， http会被关闭，而无法被重用。

32.Goroutine调度策略
gmp
33.对已经关闭的的chan进行读写，会怎么样？为什么？
* 读**已经关闭**的chan能一直读到东西，但是读到的内容根据通道内关闭前是否有元素而不同。
	* 如果chan关闭前，buffer内有元素**还未读**,会正确读到chan内的值，且返回的第二个bool值（是否读成功）为true。
	* 如果chan关闭前，buffer内有元素**已经被读完**，chan内无值，接下来所有接收的值都会非阻塞直接成功，返回 channel 元素的**零值**，但是第二个bool值一直为false。
* 写**已经关闭**的chan会panic


34.实现阻塞读的并发安全Map
锁
35.什么是goroutine leak？
goroutine leak，是go协程泄漏，什么是go协程泄漏，通俗来说，开启了一个goroutine，用完后，我们要正确让其结束。如果它没用了，还没结束，那就是goroutine leak。

泄漏的goroutine占用一部分cpu，还可能占着一些其他资源，从而影响主协程效率，有时甚至产生异常。

所以编程中一定要注意，不使用的goroutine要让其正确地终止，一定要能控制goroutine的整个生命周期。

36.data race问题怎么解决？能不能不加锁解决这个问题？
数据竞争（data race）是指在非线程安全的情况下，多线程对同一个地址空间进行写操作。一般来说，我们都会通过线程同步方法来保证数据的安全，比如采用互斥量或者读写锁。

不是所有的trace加锁都能解决
例子
循环内的i被多个goroutine同时读取，解决：外面传进去

Goroutine内共享了外部作用域的变量

未保护的全局变量，map的并发读取

平时写代码，有时发生了（data race）数据竞争却不容易发现，那么我们在构建的时候可以加上 -race 参数来检查我们的代码中是否出现数据竞争

37.epoll原理
38.etcd怎么实现分布式锁?
39.滑动窗口的概念以及应用?
40.grpc内部原理是什么？
41.http2的特点是什么,与http1.1的对比。
42.time.Now有几次系统调用？如何优化
在os中，有两个时钟:墙上时钟和单调时钟. 1. 墙上时钟. (wall time, real time) 2. 单调时钟. (monotonic time)
Linux如何获取时间呢，很简单的一个思路是， 系统启动时通过daytime服务获得一个时间t0，并记录此时的单调时钟d0。 下次获得时间时，只需要获得单调时钟d,然后d-d0+t0即可获取墙上时钟。


Now需要两次系统调用，分别获得wall ，monotonic  time
nanotime需要一个。 
粗略的说，now的开销是nanotime的两倍。
还有一种获取时间的方式是通过time.Parse,刨除各种if-else,最终调用了**unixTime**可以看出，这是不含单调时钟的。

43.空struct{}是否使用过？会在什么情况下使用，举例说明一下。
1.map。 value是空结构体，构造集合。 2.通道。 只传递信号，不传递数据。 3.切片。 不管切片多长，都不会占用空间。 4.仅包含方法的结构体。 不用指针，节约空间。 5.最后零字段。 final zero field：结构体里的最后一个属性如果是空结构体，会当成1个字节处理。如果结构体嵌套的全是空结构体，还是0个字节。

44.聊聊runtime
Golang 是有运行时(runtime)的概念的，运行时是啥？就是语言层面就形成的管理逻辑，主要工作是 goroutine 创建，调度，销毁，内存分配，垃圾回收等逻辑。有了运行时，就可以保证 golang 业务代码的简单 和 语言本身的强大。

45.介绍下你平时都是怎么调试bug以及性能问题的?



46.通过通信来共享内存，而不是通过共享内存而通信，怎么理解这句话，如何处理共享变量？
47.chan比mutex更轻么？还有更轻量的方法么？

面对一个并发问题的时候，应当选择合适的并发方式：channel还是mutex。**选择的依据是他们的能力/特性：channel的能力是让数据流动起来，擅长的是数据流动的场景**，《Channel or Mutex》中给了3个数据流动的场景：
1. 传递数据的所有权，即把某个数据发送给其他协程
2. 分发任务，每个任务都是一个数据
3. 交流异步结果，结果是一个数据
**mutex的能力是数据不动，某段时间只给一个协程访问数据的权限擅长数据位置固定的场景**，《Channel or Mutex》中给了2个数据不动场景：
1. 缓存
2. 状态，我们银行例子中的map就是一种状态
**提供解决并发问题的一个思路**：
1. 先找到数据的流动，并且还要画出来，数据流动的路径换成channel，channel的两端设计成协程
2. 基于画出来的图设计简要的channel方案，代码需要做什么
3. 这个方案是不是有点复杂，是不是用Mutex更好一点？设计一个简要的Mutex方案，对比&选择易做的、高效的


1. 关注数据的流动，就可以使用channel解决并发问题。
2. 不流动的数据，如果存在并发访问，尝试使用sync.Mutex保护数据。
3. channel不一定某个并发问题的最优解。
4. 不要害怕、拒绝使用mutex，如果mutex是问题的最优解，那就大胆使用。
5. 对于大问题，channel plus mutex也许才是更好的方案。

48.什么时候用chan不如mutex效率高？
论效率的话，channel没有mutex效率高，chan底层也是锁+各种冗余数据实现的。channel 只是用起来更加的适合golang的编程模型，搭配goroutine 写业务会很快，比较容易。