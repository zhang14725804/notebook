## 微服务可用性设计

    隔离
    超时控制
    过载保护
    限流
    降级
    重试
    负载均衡
    最佳实践

微服务问题：可用性问题、数据一致性问题

【SOP——标准操作流程】

## 隔离

保证发生故障时能限定传播范围和影响范围，让影响面变得更小

    服务隔离：动静隔离（CDN + 边缘计算）、读写隔离（主从、【CQRS】、replicaset）
    轻重隔离：核心（业务按照level进行资源划分）、快慢、热点（主动预热，被动预热）
    物理隔离：线程（tomcat线程池线程耗尽 fail fast）、进程（k8s）、集群（region.zone.cluster.appid）、机房

读写分离的文章：https://zhuanlan.zhihu.com/p/138884686

【多活架构】、【false sharing 伪共享】

同一张表同一行的数据，【经常修改的字段】和不怎么修改的字段可以分表：稿件表，稿件统计表

对于GO，所有IO都是Nonblocking，且托管给了runtime，只会阻塞Goroutine，不阻塞M，只考虑goroutine总量的控制，不需要考虑线程和线程隔离。

java除了【线程池】隔离，也有基于【信号量】的做法

### 隔离case

1. 转码集群被大视频攻击，导致转码大量延迟。根据视频大小（大，中，小）分多套处理服务

2. 入口Nginx故障，影响全机房流量入口。

3. 缩略图服务，被大图实时缩略耗光所有CPU，导致正常范围小缩略图被丢弃，大量503

4. MySQL实例【cgroup】未隔离，导致大SQL引起的集体故障

5. INFO日质量过大，导致异常ERROR日志采集延迟

【chroot namespace隔离】

播放器【硬解码】和【软解码】

## 超时控制

本质上是【快速失效 fail fast】

【连接超时，写超时，读超时】

服务器挂了如何做超时控制：（1）心跳检测（2）keep-alive 超时之后发icmp探针请求给服务器，检测是否正常

超时传递：进程间传递+跨进程传递

【SRE重要理念之SLA、SLO、SLI】

各服务之间超时时间发生变化该如何处理？核心就是有地方记录超时时间，形成君子约定

【进程内超时控制怎么做？】【进程间超时传递怎么做？gRPC】

超时异味着goroutine耗尽或者线程耗尽


### 超时case

1. 入口Nginx没有配置超时导致连锁故障（proxy timeout）

2.  依赖DB连接池没有配超时（wait:0），导致请求阻塞

3. 下游服务发版耗时增加，而上游服务配置超时过短，导致上游请求失败

## 过载保护

过载保护：当前系统负载很高，自动丢弃一些流量，以求【自保】。

设置指标（阈值），针对单个节点：【令牌桶算法】、【漏桶算法】

利特尔法则：估算系统最大吞吐量

【tcp bbr拥塞控制算法】

如何计算接近峰值时的系统吞吐？

## 限流

【分布式限流，自适应保护，客户端熔断】

过滤产生流量峰值的客户或微服务，或确保扩容失效前不会出现过载。

    （1）令牌桶、漏桶针对单个节点，无法分布式限流
    （2）QPS限流（静态QPS限流不准，不同请求需要数量迥异的资源来处理。最好按照【CPU限流】）
    （3）给每个用户限制
    （4）按优先级丢弃
    （5）拒绝请求也需要成本

分布式限流（😅😅）

    redis限流容易产生热点


【最大最小公平分配算法】、【DRF算法】

重要性：【把接口分等级、分优先级限流设置阈值】，等级传递

熔断（断路器）：客户端节流。关闭状态，打开状态，半开半闭状态。

客户端流控（retry backoff），退让算法

Gutter（双熔断）， failover：发生流量洪峰，把被拒绝的请求分给备份集群

### 限流case

1. 二层缓存穿透、大量回源导致核心服务故障

2. 异常客户端引起的服务故障

3. 用户重试导致的大面积故障

## 降级

减少工作量，丢弃不重要的请求。【降低回复的质量】，【有损服务】

    （1）用哪个指标作为流量评估和优雅降级的决定性指标（CPU，延迟，队列长度，线程数量，错误等）
    （2）进入降级模式，执行什么动作。（从cache返回数据，返回空数据）
    （3）流量抛弃或者优雅降级应该在服务的那一层实现？（BFF或者API Gateway网关）
    （4）不能经常触发，需要经常演练+SOP

降级的本质：提供有损服务

    UI模块化，非核心模块降级
    页面上一层缓存副本
    推荐值，热门推荐
    流量拦截 + 定期数据缓存

处理策略：

    页面降级，延迟服务，读写降级，缓存降级
    抛异常，返回约定协议，Mock数据，fallback处理（处理error时候的套路）


### 降级case

1. 客户端解析协议失败，app奔溃

2. 客户端部分协议不兼容，导致页面失败

3. local cache（remote cache） 数据源缓存，发版失败 + 依赖接口故障，引发白屏

4. 没有playbook（SOP标准操作手册），导致MTTR（平均修复时间）上升

## 重试

什么情况下重试？（配额不足，超时，内部错误）。限制重试次数。重试退让，重试周期。只在失败的这层进行重试，避免产生级联的重试行为。

### 重试case

1. Nginx upstream retry过大，导致服务器雪崩

2. 业务不幂等，导致重试，数据重复（全局唯一ID，业务状态，去重表）

3. 多层级重试传递，放大流量引起雪崩


## 负载均衡（服务之间的负载均衡）

    均衡的流量分发
    识别异常节点
    【scale-out】，增加同质节点扩容
    减少错误，提高可用性

backend之间的load差异比较大，CPU碎片大：每个请求处理成本不同，物理环境差异（服务器同质性差异，cgroup隔离的共享资源竞争：内存缓存，宽带，IO）

【负载均衡算法】

    （1）选择backend CPU，客户端成功率，客户端发到下游节点的请求数量，客户端到服务端的耗时情况。moving average
    （2）对新启动的节点，使用常量惩罚，使用探针方式最小化放量，进行【预热】
    （3）使用统计衰减方式，让节点指标逐渐回复到默认状态，避免进入永久黑名单


                                                                                                                   



